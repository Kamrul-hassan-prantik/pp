{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyreadstat\n",
        "import pandas as pd\n",
        "import pyreadstat\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data=pd.read_stata(\"Anxiety_data2.dta\")\n",
        "data=data[data['mental'].notna()]\n",
        "data.isnull().sum()\n",
        "data[[\"husband_edu\",\"tv\",\"radio\",\"inte\",\"newspaper\"]]=data[[\"husband_edu\",\"tv\",\"radio\",\"inte\",\"newspaper\"]].astype('category')\n",
        "\n",
        "features=['country1', 'v012', 'edu','occupation_group2', 'mstatus', 'wind1', 'v730', 'husband_edu2',\n",
        "          'husband_works_currently2', 'husband_occupation2', 'v632', 'v636', 'fper', 'v216', 'hhsex1', 'v218', 'v136', 'media1']\n",
        "#features=['country1', 'age_group', 'v106','occupation_group', 'mstatus', 'wind1', 'husband_age_group', 'husband_edu',\n",
        "          #'husband_works_currently2', 'husband_occupation', 'v632', 'v636', 'fper', 'v216', 'hhsex1', 'numofchild', 'media1']\n",
        "#features = ['v106', 'v213', 'v216', 'v632', 'v636', 'v714', 'v811', 'country1', 'age_group', 'occupation_group', 'mstatus', 'area1', 'wind1', 'husband_age_group', 'husband_edu', 'husband_works_currently2', 'husband_occupation', 'fper', 'csex1', 'hhmembers', 'hhsex1', 'numofchild', 'tv', 'radio', 'inte', 'media1', 'newspaper', 'bmi4a']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1aRJl9WcYLH",
        "outputId": "11baf6f3-af19-429c-f23c-61a3c7047b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadstat in /usr/local/lib/python3.10/dist-packages (1.2.8)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadstat) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[features].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "fNc_L6uncvb6",
        "outputId": "4e3f834b-94b3-4a43-da3f-3add78336644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "country1                     3\n",
              "v012                        35\n",
              "edu                          3\n",
              "occupation_group2            3\n",
              "mstatus                      2\n",
              "wind1                        3\n",
              "v730                        72\n",
              "husband_edu2                 5\n",
              "husband_works_currently2     2\n",
              "husband_occupation2          3\n",
              "v632                         3\n",
              "v636                         2\n",
              "fper                         3\n",
              "v216                         2\n",
              "hhsex1                       2\n",
              "v218                        13\n",
              "v136                        25\n",
              "media1                       2\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>country1</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v012</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>edu</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>occupation_group2</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mstatus</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wind1</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v730</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>husband_edu2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>husband_works_currently2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>husband_occupation2</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v632</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v636</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fper</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v216</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hhsex1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v218</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v136</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>media1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'mental'\n",
        "\n",
        "# Separate features and target\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Encode categorical features and target variable\n",
        "encoders = {}\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'object' or X[col].dtype.name == 'category':\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(X[col])\n",
        "        encoders[col] = le\n",
        "\n",
        "le_target = LabelEncoder()\n",
        "y = le_target.fit_transform(y)\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "X = pd.DataFrame(X_imputed, columns=X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joIChgQsdUap",
        "outputId": "fff51bd9-d09e-4c62-8fcb-36b1382c52cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n",
            "<ipython-input-5-384257b7568c>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = le.fit_transform(X[col])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "\n",
        "!pip install pyreadstat imbalanced-learn\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlOgUQ0VdnXJ",
        "outputId": "b75ba526-32a9-4a0f-9cd8-0a906bd96e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadstat in /usr/local/lib/python3.10/dist-packages (1.2.8)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadstat) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EoOelwlpdpu",
        "outputId": "bf56ca0d-d181-4ada-9361-9044650d6881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:02:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:06:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:11:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:24:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:24:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:24:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:24:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [10:24:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression 0.5895605072017728\n",
            "Decision Tree Accuracy: 0.6556690877754524\n",
            "Random Forest Accuracy: 0.7568632278714761\n",
            "SVM Accuracy: 0.5818047519389388\n",
            "KNN Accuracy: 0.5467191924165948\n",
            "XGBoost Accuracy: 0.7680659854733473\n",
            "Ensemble Accuracy: 0.7742213467930568\n",
            "Stacking Accuracy: 0.7732364889819032\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "logreg_model = LogisticRegression(random_state=42)\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "svm_model = SVC(probability=True, random_state=42)\n",
        "knn_model = KNeighborsClassifier()\n",
        "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Train individual models\n",
        "logreg_model.fit(X_train_smote, y_train_smote)\n",
        "dt_model.fit(X_train_smote, y_train_smote)\n",
        "rf_model.fit(X_train_smote, y_train_smote)\n",
        "svm_model.fit(X_train_smote, y_train_smote)\n",
        "knn_model.fit(X_train_smote, y_train_smote)\n",
        "xgb_model.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "base_models=[('lg', logreg_model),('dt', dt_model), ('rf', rf_model), ('svm', svm_model), ('knn', knn_model), ('xgb', xgb_model)]\n",
        "\n",
        "# Ensemble model using VotingClassifier (hard voting)\n",
        "ensemble_model = VotingClassifier(estimators=base_models, voting='hard')\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "#Ensemble model using Stacking\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(max_iter=100))\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "lg_pred = logreg_model.predict(X_test)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "ensemble_pred = ensemble_model.predict(X_test)\n",
        "stack_pred = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate models\n",
        "print(\"Logistic regression\", accuracy_score(y_test, lg_pred))\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_pred))\n",
        "print(\"Ensemble Accuracy:\", accuracy_score(y_test, ensemble_pred))\n",
        "print(\"Stacking Accuracy:\", accuracy_score(y_test, stack_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_and_print_report(model, X, y, model_name):\n",
        "    predictions = model.predict(X)\n",
        "    print(f\"\\n{model_name} Classification Report:\")\n",
        "    print(classification_report(y, predictions))\n",
        "    print(f\"{model_name} Accuracy: \", accuracy_score(y, predictions))\n",
        "\n",
        "evaluate_and_print_report(logreg_model, X_train_smote, y_train_smote, \"Logistic Train\")\n",
        "evaluate_and_print_report(dt_model, X_train_smote, y_train_smote, \"Decision Tree Train\")\n",
        "evaluate_and_print_report(rf_model, X_train_smote, y_train_smote, \"Random Forest Train\")\n",
        "evaluate_and_print_report(svm_model, X_train_smote, y_train_smote, \"SVM Train\")\n",
        "evaluate_and_print_report(knn_model, X_train_smote, y_train_smote, \"KNN Train\")\n",
        "evaluate_and_print_report(xgb_model, X_train_smote, y_train_smote, \"XGBoost Train\")\n",
        "evaluate_and_print_report(ensemble_model, X_train_smote, y_train_smote, \"Ensemble Train\")\n",
        "evaluate_and_print_report(stacking_model, X_train, y_train, \"stacking Train\")\n",
        "\n",
        "evaluate_and_print_report(logreg_model, X_test, y_test, \"Logistic Test\")\n",
        "evaluate_and_print_report(dt_model, X_test, y_test, \"Decision Tree Test\")\n",
        "evaluate_and_print_report(rf_model, X_test, y_test, \"Random Forest Test\")\n",
        "evaluate_and_print_report(svm_model, X_test, y_test, \"SVM Test\")\n",
        "evaluate_and_print_report(knn_model, X_test, y_test, \"KNN Test\")\n",
        "evaluate_and_print_report(xgb_model, X_test, y_test, \"XGBoost Test\")\n",
        "evaluate_and_print_report(ensemble_model, X_test, y_test, \"Ensemble Test\")\n",
        "evaluate_and_print_report(stacking_model, X_test, y_test, \"stacking Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkpOFcZSdzXN",
        "outputId": "d43b9f34-6ad9-4a17-ae2b-d2139c40ac72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.61      0.58     25415\n",
            "           1       0.57      0.52      0.54     25415\n",
            "\n",
            "    accuracy                           0.56     50830\n",
            "   macro avg       0.56      0.56      0.56     50830\n",
            "weighted avg       0.56      0.56      0.56     50830\n",
            "\n",
            "Logistic Train Accuracy:  0.5637418847137518\n",
            "\n",
            "Decision Tree Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     25415\n",
            "           1       1.00      0.99      0.99     25415\n",
            "\n",
            "    accuracy                           0.99     50830\n",
            "   macro avg       0.99      0.99      0.99     50830\n",
            "weighted avg       0.99      0.99      0.99     50830\n",
            "\n",
            "Decision Tree Train Accuracy:  0.9938618925831202\n",
            "\n",
            "Random Forest Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     25415\n",
            "           1       1.00      0.99      0.99     25415\n",
            "\n",
            "    accuracy                           0.99     50830\n",
            "   macro avg       0.99      0.99      0.99     50830\n",
            "weighted avg       0.99      0.99      0.99     50830\n",
            "\n",
            "Random Forest Train Accuracy:  0.9938618925831202\n",
            "\n",
            "SVM Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.60      0.58     25415\n",
            "           1       0.56      0.52      0.54     25415\n",
            "\n",
            "    accuracy                           0.56     50830\n",
            "   macro avg       0.56      0.56      0.56     50830\n",
            "weighted avg       0.56      0.56      0.56     50830\n",
            "\n",
            "SVM Train Accuracy:  0.5589022230965965\n",
            "\n",
            "KNN Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.67      0.79     25415\n",
            "           1       0.75      0.97      0.85     25415\n",
            "\n",
            "    accuracy                           0.82     50830\n",
            "   macro avg       0.85      0.82      0.82     50830\n",
            "weighted avg       0.85      0.82      0.82     50830\n",
            "\n",
            "KNN Train Accuracy:  0.8218178241196143\n",
            "\n",
            "XGBoost Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.89     25415\n",
            "           1       0.99      0.75      0.85     25415\n",
            "\n",
            "    accuracy                           0.87     50830\n",
            "   macro avg       0.89      0.87      0.87     50830\n",
            "weighted avg       0.89      0.87      0.87     50830\n",
            "\n",
            "XGBoost Train Accuracy:  0.8713554987212276\n",
            "\n",
            "Ensemble Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.68     25415\n",
            "           1       1.00      0.06      0.11     25415\n",
            "\n",
            "    accuracy                           0.53     50830\n",
            "   macro avg       0.76      0.53      0.40     50830\n",
            "weighted avg       0.76      0.53      0.40     50830\n",
            "\n",
            "Ensemble Train Accuracy:  0.5295691520755459\n",
            "\n",
            "stacking Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      1.00      0.88     25415\n",
            "           1       1.00      0.05      0.10      7074\n",
            "\n",
            "    accuracy                           0.79     32489\n",
            "   macro avg       0.90      0.53      0.49     32489\n",
            "weighted avg       0.84      0.79      0.71     32489\n",
            "\n",
            "stacking Train Accuracy:  0.7939302533165071\n",
            "\n",
            "Logistic Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.61      0.70      6287\n",
            "           1       0.28      0.51      0.36      1836\n",
            "\n",
            "    accuracy                           0.59      8123\n",
            "   macro avg       0.54      0.56      0.53      8123\n",
            "weighted avg       0.69      0.59      0.62      8123\n",
            "\n",
            "Logistic Test Accuracy:  0.5895605072017728\n",
            "\n",
            "Decision Tree Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.77      0.77      6287\n",
            "           1       0.26      0.28      0.27      1836\n",
            "\n",
            "    accuracy                           0.66      8123\n",
            "   macro avg       0.52      0.52      0.52      8123\n",
            "weighted avg       0.67      0.66      0.66      8123\n",
            "\n",
            "Decision Tree Test Accuracy:  0.6556690877754524\n",
            "\n",
            "Random Forest Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.95      0.86      6287\n",
            "           1       0.35      0.08      0.14      1836\n",
            "\n",
            "    accuracy                           0.76      8123\n",
            "   macro avg       0.56      0.52      0.50      8123\n",
            "weighted avg       0.68      0.76      0.70      8123\n",
            "\n",
            "Random Forest Test Accuracy:  0.7568632278714761\n",
            "\n",
            "SVM Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.60      0.69      6287\n",
            "           1       0.27      0.52      0.36      1836\n",
            "\n",
            "    accuracy                           0.58      8123\n",
            "   macro avg       0.54      0.56      0.52      8123\n",
            "weighted avg       0.69      0.58      0.61      8123\n",
            "\n",
            "SVM Test Accuracy:  0.5818047519389388\n",
            "\n",
            "KNN Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.56      0.66      6287\n",
            "           1       0.25      0.51      0.34      1836\n",
            "\n",
            "    accuracy                           0.55      8123\n",
            "   macro avg       0.52      0.53      0.50      8123\n",
            "weighted avg       0.67      0.55      0.58      8123\n",
            "\n",
            "KNN Test Accuracy:  0.5467191924165948\n",
            "\n",
            "XGBoost Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.98      0.87      6287\n",
            "           1       0.39      0.05      0.08      1836\n",
            "\n",
            "    accuracy                           0.77      8123\n",
            "   macro avg       0.58      0.51      0.47      8123\n",
            "weighted avg       0.69      0.77      0.69      8123\n",
            "\n",
            "XGBoost Test Accuracy:  0.7680659854733473\n",
            "\n",
            "Ensemble Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      6287\n",
            "           1       0.56      0.00      0.01      1836\n",
            "\n",
            "    accuracy                           0.77      8123\n",
            "   macro avg       0.67      0.50      0.44      8123\n",
            "weighted avg       0.73      0.77      0.68      8123\n",
            "\n",
            "Ensemble Test Accuracy:  0.7742213467930568\n",
            "\n",
            "stacking Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      1.00      0.87      6287\n",
            "           1       0.40      0.01      0.01      1836\n",
            "\n",
            "    accuracy                           0.77      8123\n",
            "   macro avg       0.59      0.50      0.44      8123\n",
            "weighted avg       0.69      0.77      0.68      8123\n",
            "\n",
            "stacking Test Accuracy:  0.7732364889819032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPYynCdti2Zb",
        "outputId": "90c9b95f-695b-4443-8bf1-af2d82fe01b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Cross-Validation Scores: [0.78224069 0.78224069 0.7820868  0.7820868  0.78236109]\n",
            "Logistic Regression Mean CV Accuracy: 0.7822032120987913\n",
            "Logistic Regression Std CV Accuracy: 0.00010472812001500021\n",
            "------------------------------\n",
            "Decision Tree Cross-Validation Scores: [0.65835642 0.66312712 0.66882118 0.66743613 0.66230568]\n",
            "Decision Tree Mean CV Accuracy: 0.6640093045761633\n",
            "Decision Tree Std CV Accuracy: 0.0037558752416413507\n",
            "------------------------------\n",
            "Random Forest Cross-Validation Scores: [0.76977532 0.77208372 0.77162204 0.77100646 0.76973988]\n",
            "Random Forest Mean CV Accuracy: 0.7708454829141257\n",
            "Random Forest Std CV Accuracy: 0.0009518187237152879\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "#cross validation score of each model\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def evaluate_with_cross_validation(model, X, y, cv=5, scoring='accuracy'):\n",
        "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
        "    return scores\n",
        "\n",
        "# Evaluate models with cross-validation\n",
        "models = {\n",
        "    'Logistic Regression': logreg_model,\n",
        "    'Decision Tree': dt_model,\n",
        "    'Random Forest': rf_model,\n",
        "    'SVM': svm_model,\n",
        "    'KNN': knn_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'Ensemble': ensemble_model,\n",
        "    #'Stacking': stacking_model # Uncomment if you use stacking model\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    cv_scores = evaluate_with_cross_validation(model, X_train, y_train)\n",
        "    print(f\"{model_name} Cross-Validation Scores: {cv_scores}\")\n",
        "    print(f\"{model_name} Mean CV Accuracy: {cv_scores.mean()}\")\n",
        "    print(f\"{model_name} Std CV Accuracy: {cv_scores.std()}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vneCXRKGBLGZ",
        "outputId": "c03f0522-fe7d-401a-cad3-e27817b19624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC for Logistic Regression: 0.5848186578591991\n",
            "AUROC for Decision Tree: 0.522559996021808\n",
            "AUROC for Random Forest: 0.5870364219420161\n",
            "AUROC for SVM: 0.5846600326502833\n",
            "AUROC for KNN: 0.5400280881841806\n",
            "AUROC for XGBoost: 0.601749104993428\n",
            "AUROC calculation not supported for Ensemble (predict_proba not available)\n",
            "AUROC for Stacking: 0.6055521248847346\n"
          ]
        }
      ],
      "source": [
        "# prompt: perform Auroc for all models\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Assuming you have already trained your models and have X_test and y_test\n",
        "#ann model\n",
        "models = {\n",
        "    'Logistic Regression': logreg_model,\n",
        "    'Decision Tree': dt_model,\n",
        "    'Random Forest': rf_model,\n",
        "    'SVM': svm_model,\n",
        "    'KNN': knn_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'Ensemble': ensemble_model,\n",
        "    'Stacking': stacking_model\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    try:\n",
        "        # Predict probabilities for the positive class\n",
        "        y_prob = model.predict_proba(X_test)[:, 1]  # Assuming binary classification\n",
        "        auroc = roc_auc_score(y_test, y_prob)\n",
        "        print(f\"AUROC for {model_name}: {auroc}\")\n",
        "    except AttributeError:\n",
        "        print(f\"AUROC calculation not supported for {model_name} (predict_proba not available)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}